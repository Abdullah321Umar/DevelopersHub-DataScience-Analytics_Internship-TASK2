{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8312d718-25db-4f35-bc30-7399581e25ae",
   "metadata": {},
   "source": [
    "# Task 2: Credit Risk Prediction \n",
    "## Objective: \n",
    " #### Predict whether a loan applicant is likely to default on a loan. \n",
    "## Dataset: \n",
    " #### Loan Prediction Dataset (available on Kaggle) \n",
    "## Instructions: \n",
    "#### ● Handle missing data appropriately. \n",
    "#### ● Visualize key features such as loan amount, education, and income. \n",
    "#### ● Train a classification model like Logistic Regression or Decision Tree. \n",
    "#### ● Evaluate the model using accuracy and a confusion matrix. \n",
    "## Skills: \n",
    "#### ● Data cleaning and handling missing values \n",
    "#### ● Exploratory Data Analysis (EDA) \n",
    "#### ● Binary classification using machine learning \n",
    "#### ● Model evaluation using confusion matrix and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2de9d-bbc1-4461-8bcb-57bba3087437",
   "metadata": {},
   "source": [
    "# Here's The Python Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3afa501-81f1-40c8-b808-d14d47f13626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Credit Risk Prediction pipeline...\n",
      "Loaded dataset with shape: (614, 13)\n",
      "\n",
      "--- Dataset overview ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      " Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed        32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n",
      "\n",
      "Sample rows:\n",
      "     Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n",
      "Creating visualizations and saving to: C:\\Users\\Abdullah Umer\\Desktop\\DevelopersHub Corporation Internship\\TASK 2\\output\n",
      "Visualizations saved.\n",
      "\n",
      "Training model: LogisticRegression\n",
      "LogisticRegression Accuracy: 0.8618\n",
      "Confusion Matrix:\n",
      " [[22 16]\n",
      " [ 1 84]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72        38\n",
      "           1       0.84      0.99      0.91        85\n",
      "\n",
      "    accuracy                           0.86       123\n",
      "   macro avg       0.90      0.78      0.81       123\n",
      "weighted avg       0.88      0.86      0.85       123\n",
      "\n",
      "\n",
      "Training model: DecisionTree\n",
      "DecisionTree Accuracy: 0.7480\n",
      "Confusion Matrix:\n",
      " [[27 11]\n",
      " [20 65]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.71      0.64        38\n",
      "           1       0.86      0.76      0.81        85\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.71      0.74      0.72       123\n",
      "weighted avg       0.77      0.75      0.75       123\n",
      "\n",
      "\n",
      "Best model: LogisticRegression with accuracy 0.8618\n",
      "\n",
      "All done. Check the 'output' folder next to your dataset for saved visualizations and confusion matrices.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Task 2: \n",
    "   (Credit Risk Prediction) \"\"\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Configuration -----------------------\n",
    "DATA_PATH = r\"C:/Users/Abdullah Umer/Desktop/DevelopersHub Corporation Internship/TASK 2/Credit Risk Prediction DataSet.csv\"\n",
    "DATA_DIR = Path(DATA_PATH).parent\n",
    "OUTPUT_DIR = DATA_DIR / \"output\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Visualization style choices\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.facecolor\"] = \"#9400D3\"\n",
    "plt.rcParams[\"axes.facecolor\"] = \"#ffffff\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"#FFFFFF\"\n",
    "plt.rcParams[\"axes.labelcolor\"] = \"#FFFFFF\"\n",
    "plt.rcParams[\"xtick.color\"] = \"#F7DFDF\"\n",
    "plt.rcParams[\"ytick.color\"] = \"#F7DCDC\"\n",
    "\n",
    "\n",
    "# Use a friendly palette for plots\n",
    "PALETTE = sns.color_palette(\"dark\")\n",
    "DIVERGING = sns.color_palette(\"RdYlBu\", as_cmap=False)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Helper Functions -----------------------\n",
    "\n",
    "def save_fig(fig, name: str):\n",
    "    path = OUTPUT_DIR / f\"{name}.png\"\n",
    "    fig.savefig(path, bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Loaded dataset with shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def overview(df: pd.DataFrame):\n",
    "    print(\"\\n--- Dataset overview ---\")\n",
    "    print(df.info())\n",
    "    print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
    "    print(\"\\nSample rows:\\n\", df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Preprocessing -----------------------\n",
    "\n",
    "def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Handle missing values using sensible defaults:\n",
    "    - Numerical: median\n",
    "    - Categorical: mode\n",
    "    - Loan_ID left as is (identifier)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Identify numeric and categorical cols\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # Some numeric-like columns might be parsed as object\n",
    "    # We'll explicitly convert known numeric columns if present\n",
    "    for col in [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Credit_History\"]:\n",
    "        if col in df.columns and df[col].dtype == object:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "    # Fill numerics with median\n",
    "    for col in numeric_cols:\n",
    "        med = df[col].median()\n",
    "        df[col] = df[col].fillna(med)\n",
    "\n",
    "    # Fill categoricals with mode\n",
    "    for col in cat_cols:\n",
    "        if df[col].isnull().any():\n",
    "            mode = df[col].mode()\n",
    "            if not mode.empty:\n",
    "                df[col] = df[col].fillna(mode[0])\n",
    "            else:\n",
    "                df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Standardize Loan_Status target to 0/1\n",
    "    if \"Loan_Status\" in df.columns:\n",
    "        df[\"Loan_Status\"] = df[\"Loan_Status\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "    # Clean Dependents: replace '3+' with 3 and convert to numeric\n",
    "    if \"Dependents\" in df.columns:\n",
    "        df[\"Dependents\"] = df[\"Dependents\"].replace(\"3+\", \"3\")\n",
    "        df[\"Dependents\"] = pd.to_numeric(df[\"Dependents\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    # Create TotalIncome\n",
    "    if all(col in df.columns for col in [\"ApplicantIncome\", \"CoapplicantIncome\"]):\n",
    "        df[\"TotalIncome\"] = df[\"ApplicantIncome\"] + df[\"CoapplicantIncome\"]\n",
    "\n",
    "    # Log transform skewed numeric features for better plots & modelling\n",
    "    for col in [\"LoanAmount\", \"ApplicantIncome\", \"CoapplicantIncome\", \"TotalIncome\"]:\n",
    "        if col in df.columns:\n",
    "            # create a safe log column\n",
    "            new_col = f\"{col}_log\"\n",
    "            df[new_col] = np.log1p(df[col].astype(float))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Visualizations (20 plots) -----------------------\n",
    "\n",
    "def create_visualizations(df: pd.DataFrame):\n",
    "    \"\"\"Create and save 20 high-quality visualizations in the output folder.\"\"\"\n",
    "    print(\"Creating visualizations and saving to:\", OUTPUT_DIR)\n",
    "\n",
    "    # Ensure categorical mapping for plotting\n",
    "    if \"Loan_Status\" in df.columns:\n",
    "        df[\"Loan_Status_Label\"] = df[\"Loan_Status\"].map({1: \"Approved/No Default\", 0: \"Not Approved/Default\"})\n",
    "    else:\n",
    "        df[\"Loan_Status_Label\"] = \"Unknown\"\n",
    "\n",
    "    # 1. LoanAmount distribution (hist)\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[\"LoanAmount\"].dropna(), kde=True, palette=PALETTE, color=\"purple\")\n",
    "    plt.title(\"Loan Amount Distribution\")\n",
    "    save_fig(fig, \"01_loanamount_distribution\")\n",
    "\n",
    "    # 2. LoanAmount (log) distribution\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[\"LoanAmount_log\"], kde=True, color=\"green\")\n",
    "    plt.title(\"Loan Amount (log) Distribution\")\n",
    "    save_fig(fig, \"02_loanamount_log_distribution\")\n",
    "\n",
    "    # 3. ApplicantIncome distribution\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[\"ApplicantIncome\"], bins=40)\n",
    "    plt.title(\"Applicant Income Distribution\")\n",
    "    save_fig(fig, \"03_applicantincome_distribution\")\n",
    "\n",
    "    # 4. ApplicantIncome (log)\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[\"ApplicantIncome_log\"], bins=40, color=\"violet\")\n",
    "    plt.title(\"Applicant Income (log) Distribution\")\n",
    "    save_fig(fig, \"04_applicantincome_log\")\n",
    "\n",
    "    # 5. TotalIncome (log)\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[\"TotalIncome_log\"].dropna(), kde=True, color=\"red\")\n",
    "    plt.title(\"Total Income (log) Distribution\")\n",
    "    save_fig(fig, \"05_totalincome_log\")\n",
    "\n",
    "    # 6. Countplot: Education vs Loan Status\n",
    "    if \"Education\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.countplot(data=df, x=\"Education\", hue=\"Loan_Status_Label\", palette=\"Set2\")\n",
    "        plt.title(\"Education vs Loan Status\")\n",
    "        save_fig(fig, \"06_education_vs_loanstatus\")\n",
    "\n",
    "    # 7. Countplot: Self_Employed vs Loan Status\n",
    "    if \"Self_Employed\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.countplot(data=df, x=\"Self_Employed\", hue=\"Loan_Status_Label\", palette=\"Set1\")\n",
    "        plt.title(\"Self Employed vs Loan Status\")\n",
    "        save_fig(fig, \"07_selfemployed_vs_loanstatus\")\n",
    "\n",
    "    # 8. Credit History vs Loan Status\n",
    "    if \"Credit_History\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.barplot(data=df, x=\"Credit_History\", y=\"LoanAmount\", ci=None, palette=\"Accent\")\n",
    "        plt.title(\"Credit History vs Average Loan Amount\")\n",
    "        save_fig(fig, \"08_credithistory_vs_loanamount\")\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.countplot(data=df, x=\"Credit_History\", hue=\"Loan_Status_Label\", palette=\"dark\")\n",
    "        plt.title(\"Credit History vs Loan Status\")\n",
    "        save_fig(fig, \"09_credithistory_vs_loanstatus\")\n",
    "\n",
    "    # 10. Property Area vs Loan Status\n",
    "    if \"Property_Area\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.countplot(data=df, x=\"Property_Area\", hue=\"Loan_Status_Label\", palette=\"tab10\")\n",
    "        plt.title(\"Property Area vs Loan Status\")\n",
    "        save_fig(fig, \"10_propertyarea_vs_loanstatus\")\n",
    "\n",
    "    # 11. Boxplot: LoanAmount by Education\n",
    "    if \"Education\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.boxplot(data=df, x=\"Education\", y=\"LoanAmount\", palette=\"pastel\")\n",
    "        plt.title(\"Loan Amount by Education\")\n",
    "        save_fig(fig, \"11_loanamount_by_education\")\n",
    "\n",
    "    # 12. Boxplot: TotalIncome by Loan Status\n",
    "    if \"TotalIncome\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.boxplot(data=df, x=\"Loan_Status_Label\", y=\"TotalIncome\", palette=\"muted\")\n",
    "        plt.title(\"Total Income by Loan Status\")\n",
    "        save_fig(fig, \"12_totalincome_by_loanstatus\")\n",
    "\n",
    "    # 13. Scatter: TotalIncome vs LoanAmount\n",
    "    if \"TotalIncome\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(data=df, x=\"TotalIncome\", y=\"LoanAmount\", hue=\"Loan_Status_Label\", palette=\"Dark2\")\n",
    "        plt.title(\"Total Income vs Loan Amount\")\n",
    "        save_fig(fig, \"13_totalincome_vs_loanamount\")\n",
    "\n",
    "    # 14. Violin: ApplicantIncome_log by Loan Status\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.violinplot(data=df, x=\"Loan_Status_Label\", y=\"ApplicantIncome_log\", palette=\"Set3\")\n",
    "    plt.title(\"Applicant Income (log) by Loan Status\")\n",
    "    save_fig(fig, \"14_applicantincome_log_violin_by_status\")\n",
    "\n",
    "    # 15. Heatmap: Correlation among numeric features\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    corr = numeric_df.corr()\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"RdYlBu\")\n",
    "    plt.title(\"Correlation Matrix (numeric features)\")\n",
    "    save_fig(fig, \"15_correlation_heatmap\")\n",
    "\n",
    "    # 16. Countplot: Gender vs Loan Status\n",
    "    if \"Gender\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        sns.countplot(data=df, x=\"Gender\", hue=\"Loan_Status_Label\", palette=\"Set2\")\n",
    "        plt.title(\"Gender vs Loan Status\")\n",
    "        save_fig(fig, \"16_gender_vs_loanstatus\")\n",
    "\n",
    "    # 17. Bar: Mean LoanAmount by Dependents\n",
    "    if \"Dependents\" in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        df_group = df.groupby(\"Dependents\")[\"LoanAmount\"].mean().reset_index()\n",
    "        sns.barplot(data=df_group, x=\"Dependents\", y=\"LoanAmount\", palette=\"Greens_d\")\n",
    "        plt.title(\"Average Loan Amount by Dependents\")\n",
    "        save_fig(fig, \"17_avgloanamount_by_dependents\")\n",
    "\n",
    "    # 18. KDE plots of LoanAmount_log by Loan Status\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(data=df, x=\"LoanAmount_log\", hue=\"Loan_Status_Label\", fill=True)\n",
    "    plt.title(\"KDE of Loan Amount (log) by Loan Status\")\n",
    "    save_fig(fig, \"18_kde_loanamount_log_by_status\")\n",
    "\n",
    "    # 19. Pairplot of selected numeric log features\n",
    "    pair_cols = [c for c in df.columns if c.endswith(\"_log\")][:4]\n",
    "    if len(pair_cols) >= 2:\n",
    "        # Pairplot is large; save separately\n",
    "        pp = sns.pairplot(df[pair_cols + [\"Loan_Status_Label\"]], hue=\"Loan_Status_Label\", diag_kind=\"kde\", corner=True)\n",
    "        pp.fig.suptitle(\"Pairplot of log-features (subset)\", y=1.02)\n",
    "        pp_filename = OUTPUT_DIR / \"19_pairplot_log_features.png\"\n",
    "        pp.fig.savefig(pp_filename, bbox_inches=\"tight\", dpi=150)\n",
    "        plt.close(pp.fig)\n",
    "\n",
    "    # 20. Stacked bar: Loan Status proportion by Property Area\n",
    "    if \"Property_Area\" in df.columns:\n",
    "        prop = pd.crosstab(df[\"Property_Area\"], df[\"Loan_Status_Label\"], normalize=\"index\")\n",
    "        fig = prop.plot(kind=\"bar\", stacked=True, figsize=(8, 6)).get_figure()\n",
    "        plt.title(\"Proportion of Loan Status by Property Area\")\n",
    "        save_fig(fig, \"20_stacked_prop_loanstatus_by_propertyarea\")\n",
    "\n",
    "    print(\"Visualizations saved.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------- Modelling ---------------------------------------\n",
    "\n",
    "def prepare_model_data(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop identifiers\n",
    "    if \"Loan_ID\" in df.columns:\n",
    "        df = df.drop(columns=[\"Loan_ID\"])\n",
    "\n",
    "    # Ensure target exists\n",
    "    if \"Loan_Status\" not in df.columns:\n",
    "        raise ValueError(\"Loan_Status target column not found in dataframe.\")\n",
    "\n",
    "    # Separate X and y\n",
    "    y = df[\"Loan_Status\"].astype(int)\n",
    "    X = df.drop(columns=[\"Loan_Status\", \"Loan_Status_Label\"], errors=True)\n",
    "\n",
    "    # Categorical columns to encode\n",
    "    cat_cols = X.select_dtypes(include=[object]).columns.tolist()\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    # One-hot encode categoricals (drop_first to avoid multicollinearity)\n",
    "    X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # Fill any remaining NA\n",
    "    X_encoded = X_encoded.fillna(X_encoded.median())\n",
    "\n",
    "    return X_encoded, y\n",
    "\n",
    "\n",
    "def train_and_evaluate(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Scale numeric features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining model: {name}\")\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        preds = model.predict(X_test_scaled)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        cr = classification_report(y_test, preds)\n",
    "\n",
    "        results[name] = {\"model\": model, \"accuracy\": acc, \"confusion_matrix\": cm, \"report\": cr}\n",
    "\n",
    "        print(f\"{name} Accuracy: {acc:.4f}\")\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "        print(\"Classification Report:\\n\", cr)\n",
    "\n",
    "        # Save confusion matrix heatmap\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"RdBu\", cbar=False, ax=ax)\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"Actual\")\n",
    "        ax.set_title(f\"Confusion Matrix - {name}\")\n",
    "        save_fig(fig, f\"confusion_matrix_{name.lower()}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------- Main ----------------------------------\n",
    "\n",
    "def main():\n",
    "    print(\"Starting Credit Risk Prediction pipeline...\")\n",
    "\n",
    "    # Load\n",
    "    df = load_data(DATA_PATH)\n",
    "\n",
    "    # Quick overview\n",
    "    overview(df)\n",
    "\n",
    "    # Clean missing values\n",
    "    df_clean = handle_missing_values(df)\n",
    "\n",
    "    # Feature engineering\n",
    "    df_feat = feature_engineering(df_clean)\n",
    "\n",
    "    # Visualizations\n",
    "    create_visualizations(df_feat)\n",
    "\n",
    "    # Modelling data\n",
    "    X, y = prepare_model_data(df_feat)\n",
    "\n",
    "    # Train & evaluate\n",
    "    results = train_and_evaluate(X, y)\n",
    "\n",
    "    # Summarize best model\n",
    "    best_model_name = max(results.keys(), key=lambda k: results[k][\"accuracy\"])\n",
    "    best_acc = results[best_model_name][\"accuracy\"]\n",
    "    print(f\"\\nBest model: {best_model_name} with accuracy {best_acc:.4f}\")\n",
    "\n",
    "    print(\"\\nAll done. Check the 'output' folder next to your dataset for saved visualizations and confusion matrices.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab38170-a1d0-4206-9922-634e88ddfde2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
